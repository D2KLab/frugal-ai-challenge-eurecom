{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3114dcac-9f1c-49bd-80a3-1d28349b8d19",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfafa51-0ad9-497e-bb05-7e873012c04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from huggingface_hub import PyTorchModelHubMixin\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import torch\n",
    "import sklearn.metrics as metrics\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from torch.optim import AdamW\n",
    "import copy\n",
    "\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f7e386-958b-4c7b-b60a-a7d883d77d28",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25c711f-5766-44c6-8d11-dbeb3aa1bcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "FINAL_SUBMISSION = False # If true, trains on the full set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3036f470-90f2-4532-b01e-7b0e152251c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"quotaclimat/frugalaichallenge-text-train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debd20ed-ff75-4e44-9877-45d07878bb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = [\n",
    "    '0_not_relevant',\n",
    "    '1_not_happening'\n",
    "    '2_not_human',\n",
    "    '3_not_bad',\n",
    "    '4_solutions_harmful_unnecessary',\n",
    "    '5_science_unreliable',\n",
    "    '6_proponents_biased',\n",
    "    '7_fossil_fuels_needed'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352ca1b5-badc-4465-a329-bcf1604e4477",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = dataset['train']\n",
    "data_test = dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b94ee54-aacb-4c95-8e93-03e7d8b8f37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = [t['quote'] for t in data_train]\n",
    "test_texts = [t['quote'] for t in data_test]\n",
    "\n",
    "\n",
    "\n",
    "labels_train = [int(t['label'][0]) for t in data_train]\n",
    "labels_test = [int(t['label'][0]) for t in data_test]\n",
    "\n",
    "\n",
    "if FINAL_SUBMISSION:\n",
    "    train_texts = train_texts+test_texts\n",
    "    labels_train = labels_train+labels_test\n",
    "\n",
    "# classes weights for CE Loss\n",
    "weights_tmp = []\n",
    "for i in range(0, 8):\n",
    "    weights_tmp.append(labels_train.count(i))\n",
    "\n",
    "weights = [len(labels_train)/(w+1) for w in weights_tmp]\n",
    "\n",
    "weights = torch.FloatTensor(weights).to(device)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20067062-c941-4d49-adc0-e560074e18e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_model = SentenceTransformer(\"sentence-transformers/sentence-t5-large\")\n",
    "batch_size = 2\n",
    "\n",
    "train_tokens = torch.Tensor(emb_model.encode(train_texts))\n",
    "train_labels = labels_train\n",
    "train_labels = torch.tensor(train_labels)\n",
    "train_data = TensorDataset(train_tokens, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "test_tokens = torch.Tensor(emb_model.encode(test_texts))\n",
    "test_labels = labels_test\n",
    "test_labels = torch.tensor(test_labels)\n",
    "test_data = TensorDataset(test_tokens, test_labels)\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557e55e4-81fb-4b72-999f-fd08bfcc3580",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c13d6a4-96e2-41b9-a260-3aca6dd7fd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConspiracyClassification(\n",
    "    nn.Module,\n",
    "    PyTorchModelHubMixin, \n",
    "    # optionally, you can add metadata which gets pushed to the model card\n",
    "):    \n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.h1 = nn.Linear(768, 100)\n",
    "        self.h2 = nn.Linear(100, 100)\n",
    "        self.h3 = nn.Linear(100, 100)\n",
    "        self.h4 = nn.Linear(100, 50)\n",
    "        self.h5 = nn.Linear(50, num_classes)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "        \n",
    "    def forward(self, input_texts):\n",
    "        outputs = self.h1(input_texts)\n",
    "        outputs = self.activation(outputs)\n",
    "        outputs = self.dropout(outputs)\n",
    "        outputs = self.h2(outputs)\n",
    "        outputs = self.activation(outputs)\n",
    "        outputs = self.dropout(outputs)\n",
    "        outputs = self.h3(outputs)\n",
    "        outputs = self.activation(outputs)\n",
    "        outputs = self.dropout(outputs)\n",
    "        outputs = self.h4(outputs)\n",
    "        outputs = self.activation(outputs)\n",
    "        outputs = self.dropout(outputs)\n",
    "        outputs = self.h5(outputs)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d01a744-115d-47bc-a12f-103512c152dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "config = {\"num_classes\": 8}\n",
    "model = ConspiracyClassification(**config)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7da29a4-20ad-4f36-b83d-d82d30328f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr=5e-4,\n",
    "                  weight_decay = 0.01)\n",
    "\n",
    "scheduler = ReduceLROnPlateau(optimizer, patience=4, factor=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491e71c8-503d-4a80-8338-24d89e670e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(weight = weights)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4272a9d-94d0-4b4e-9dab-5744fba3f22e",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6620b15e-f9e2-4f31-a7ec-6daebf47722d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 15\n",
    "\n",
    "best_MCCA = 0\n",
    "best_F1 = 0\n",
    "best_loss = 999\n",
    "best_ACC = 0\n",
    "results = []\n",
    "\n",
    "best_state_dict = model.state_dict()\n",
    "\n",
    "for e in trange(0, epochs, position=0, leave=True):\n",
    "\n",
    "    print('Starting epoch ', e)\n",
    "    model.train()\n",
    "        \n",
    "    tr_loss = 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    x_features = []\n",
    "    y_true = []\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_tokens, b_labels = batch            \n",
    "        b_labels = b_labels.float()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        logits = model(b_tokens)\n",
    "        \n",
    "            \n",
    "        loss = criterion(logits, b_labels.long())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        tr_loss += loss.item()\n",
    "        nb_tr_examples += b_input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "    \n",
    "    print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
    "    \n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    predictions_sep = []\n",
    "    labels_sep = []\n",
    "    \n",
    "    eval_loss = 0\n",
    "    steps=0\n",
    "    x_features = []\n",
    "    y_true = []\n",
    "    for step, batch in enumerate(test_dataloader):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        b_tokens, b_labels = batch\n",
    "        b_labels = b_labels.float()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "\n",
    "            logits = model(b_tokens)\n",
    "            loss = criterion(logits, b_labels.long())\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            ground_truth = b_labels.detach().cpu().numpy()\n",
    "            steps+=1\n",
    "            eval_loss+=loss.detach().item()\n",
    "            predictions_sep.extend(logits.argmax(1))\n",
    "            for l in ground_truth:\n",
    "                labels_sep.append(l)\n",
    "        \n",
    "    scheduler.step(eval_loss/steps)\n",
    "    LOSS = eval_loss/steps\n",
    "    \n",
    "    ACC = metrics.accuracy_score(labels_sep, predictions_sep)\n",
    "    F1 = metrics.f1_score(labels_sep, predictions_sep, average='macro')\n",
    "    MCCA = metrics.matthews_corrcoef(labels_sep, predictions_sep)\n",
    "    \n",
    "    if ACC> best_ACC:\n",
    "        best_MCCA = MCCA\n",
    "        best_ACC = ACC\n",
    "        best_F1 = F1\n",
    "        best_loss = LOSS\n",
    "        best_state_dict = copy.deepcopy(model.state_dict())\n",
    "        best_epoch = e\n",
    "        \n",
    "    results.append([LOSS, ACC, F1, MCCA])\n",
    "    print(\"\\t Eval loss: {}\".format(LOSS))\n",
    "    print(\"\\t Eval ACC: {}\".format(ACC))\n",
    "    print(\"\\t Eval F1: {}\".format(F1))\n",
    "    print(\"\\t Eval MCCA: {}\".format(MCCA))\n",
    "    print(\"---\"*25)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f498edf9-dc6c-4701-9f2f-6794599ea42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(best_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceec3430-8f23-402f-94cd-c157caa2845a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "HF_token = \"<YOUR_TOKEN>\"\n",
    "login(HF_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915ed9b5-704d-4c47-b123-f4336b7e8b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"./sbert+mlp_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946951d0-1c63-49b9-b3a0-64c536156be5",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a707db8-8340-418e-970b-f9479aa1e3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from huggingface_hub import PyTorchModelHubMixin\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import torch\n",
    "import sklearn.metrics as metrics\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from torch.optim import AdamW\n",
    "import copy\n",
    "\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072ec8e9-c60b-403b-b736-ecddae0e67ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConspiracyClassification768(\n",
    "    nn.Module,\n",
    "    PyTorchModelHubMixin, \n",
    "    # optionally, you can add metadata which gets pushed to the model card\n",
    "):    \n",
    "    def __init__(self, num_classes=8):\n",
    "        super().__init__()\n",
    "        self.h1 = nn.Linear(768, 100)\n",
    "        self.h2 = nn.Linear(100, 100)\n",
    "        self.h3 = nn.Linear(100, 100)\n",
    "        self.h4 = nn.Linear(100, 50)\n",
    "        self.h5 = nn.Linear(50, num_classes)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "        \n",
    "    def forward(self, input_texts):\n",
    "        outputs = self.h1(input_texts)\n",
    "        outputs = self.activation(outputs)\n",
    "        outputs = self.dropout(outputs)\n",
    "        outputs = self.h2(outputs)\n",
    "        outputs = self.activation(outputs)\n",
    "        outputs = self.dropout(outputs)\n",
    "        outputs = self.h3(outputs)\n",
    "        outputs = self.activation(outputs)\n",
    "        outputs = self.dropout(outputs)\n",
    "        outputs = self.h4(outputs)\n",
    "        outputs = self.activation(outputs)\n",
    "        outputs = self.dropout(outputs)\n",
    "        outputs = self.h5(outputs)\n",
    "        \n",
    "        return outputs  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d075a78e-0ecc-4cc8-a9ad-ce7800df5551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the label mapping\n",
    "LABEL_MAPPING = {\n",
    "    \"0_not_relevant\": 0,\n",
    "    \"1_not_happening\": 1,\n",
    "    \"2_not_human\": 2,\n",
    "    \"3_not_bad\": 3,\n",
    "    \"4_solutions_harmful_unnecessary\": 4,\n",
    "    \"5_science_unreliable\": 5,\n",
    "    \"6_proponents_biased\": 6,\n",
    "    \"7_fossil_fuels_needed\": 7\n",
    "}\n",
    "\n",
    "# Load and prepare the dataset\n",
    "dataset = load_dataset(\"quotaclimat/frugalaichallenge-text-train\")\n",
    "\n",
    "# Convert string labels to integers\n",
    "dataset = dataset.map(lambda x: {\"label\": LABEL_MAPPING[x[\"label\"]]})\n",
    "\n",
    "# Split dataset\n",
    "train_test = dataset[\"train\"]\n",
    "test_dataset = dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ace7ab9-9775-445b-a64e-044629ed0511",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConspiracyClassification768.from_pretrained(\"ypesk/frugal-ai-mlp-768-fullset\")\n",
    "model = model.to(device)\n",
    "emb_model = SentenceTransformer(\"sentence-transformers/sentence-t5-large\")\n",
    "batch_size = 6\n",
    "\n",
    "test_tokens = torch.Tensor(emb_model.encode([t['quote'] for t in test_dataset]))\n",
    "test_data = TensorDataset(test_tokens)\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a029adb3-74dc-4a8d-8c35-3525417b3539",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for batch in tqdm(test_dataloader):\n",
    "\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    with torch.no_grad():\n",
    "        b_tokens = batch[0]\n",
    "        logits = model(b_tokens)\n",
    "            \n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    predictions.extend(logits.argmax(1))\n",
    "    \n",
    "\n",
    "true_labels = test_dataset[\"label\"]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896ac43e-81a1-4c57-96ee-9aa6a77c0192",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACC = metrics.accuracy_score(true_labels, predictions)\n",
    "F1 = metrics.f1_score(true_labels, predictions, average='macro')\n",
    "MCCA = metrics.matthews_corrcoef(true_labels, predictions)\n",
    "\n",
    "print(round(ACC, 3),\";\", round(F1, 3), \";\", round(MCCA, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94014700-fd4f-4465-b822-d1c2aa32b038",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = \"\"\n",
    "for i in range(0, 8):\n",
    "    l = []\n",
    "    p = []\n",
    "    for j in range(0, len(true_labels)):\n",
    "        if true_labels[j]==i:\n",
    "            l.append(true_labels[j])\n",
    "            p.append(predictions[j])\n",
    "            \n",
    "    \n",
    "    acc_c = metrics.accuracy_score(l, p)\n",
    "    txt+=str(round(acc_c, 3))\n",
    "    txt+=\";\"\n",
    "\n",
    "# Accuracy per class\n",
    "print(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47a0cf0-d99d-4c9b-b563-31461c978423",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a9af1a-1dd7-409d-b513-8fd58385a75a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539bd28b-b670-4e7d-9db9-18f4c6ceef7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
